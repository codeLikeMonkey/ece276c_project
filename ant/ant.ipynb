{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-06-12 21:55:58,285] Making new env: Ant-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value: 4.545334453565605 for episode: 0 and reward: 90.9066890713121\n",
      "Average value: 7.62156236266325 for episode: 1 and reward: 66.06989263551849\n",
      "Average value: 39.82448811791512 for episode: 2 and reward: 651.6800774677006\n",
      "Average value: 71.4703601339184 for episode: 3 and reward: 672.7419284379807\n",
      "Average value: 108.93263189181697 for episode: 4 and reward: 820.7157952918895\n",
      "Average value: 145.12788295624648 for episode: 5 and reward: 832.837653180407\n",
      "Average value: 180.09976662838253 for episode: 6 and reward: 844.5655563989675\n",
      "Average value: 211.15591480354198 for episode: 7 and reward: 801.2227301315717\n",
      "Average value: 243.16232911357963 for episode: 8 and reward: 851.2842010042951\n",
      "Average value: 271.6039909475042 for episode: 9 and reward: 811.9955657920716\n",
      "Average value: 298.46236648134584 for episode: 10 and reward: 808.7715016243371\n",
      "Average value: 326.3956307819026 for episode: 11 and reward: 857.127652492481\n",
      "Average value: 346.5022835766027 for episode: 12 and reward: 728.5286866759038\n",
      "Average value: 364.0813720790713 for episode: 13 and reward: 698.0840536259756\n",
      "Average value: 386.15751932498273 for episode: 14 and reward: 805.6043169973012\n",
      "Average value: 382.2832034198077 for episode: 15 and reward: 308.671201221482\n",
      "Average value: 405.14443547371803 for episode: 16 and reward: 839.5078444980143\n",
      "Average value: 423.7436175933326 for episode: 17 and reward: 777.1280778660093\n",
      "Average value: 434.74988228781325 for episode: 18 and reward: 643.868911482946\n",
      "Average value: 455.08867739541375 for episode: 19 and reward: 841.5257844398238\n",
      "Average value: 472.76901895236784 for episode: 20 and reward: 808.6955085344955\n",
      "Average value: 488.8985572316142 for episode: 21 and reward: 795.3597845372948\n",
      "Average value: 507.9646356471658 for episode: 22 and reward: 870.2201255426457\n",
      "Average value: 519.8813506929596 for episode: 23 and reward: 746.2989365630435\n",
      "Average value: 531.9581361777695 for episode: 24 and reward: 761.4170603891586\n",
      "Average value: 545.6382458466701 for episode: 25 and reward: 805.5603295557842\n",
      "Average value: 554.8776947009636 for episode: 26 and reward: 730.4272229325428\n",
      "Average value: 569.9923592373023 for episode: 27 and reward: 857.1709854277376\n",
      "Average value: 571.5646519146524 for episode: 28 and reward: 601.4382127843057\n",
      "Average value: 577.6980652836222 for episode: 29 and reward: 694.2329192940499\n",
      "Average value: 593.1914060396066 for episode: 30 and reward: 887.5648804033119\n",
      "Average value: 607.0712770891622 for episode: 31 and reward: 870.7888270307202\n",
      "Average value: 614.6752367775355 for episode: 32 and reward: 759.1504708566281\n",
      "Average value: 623.5183092532242 for episode: 33 and reward: 791.5366862913102\n",
      "Average value: 635.3162944134673 for episode: 34 and reward: 859.4780124580874\n",
      "Average value: 645.1136372569734 for episode: 35 and reward: 831.2631512835903\n",
      "Average value: 654.0778706508223 for episode: 36 and reward: 824.3983051339528\n",
      "Average value: 660.914530866984 for episode: 37 and reward: 790.811074974057\n",
      "Average value: 671.9159100104516 for episode: 38 and reward: 880.9421137363364\n",
      "Average value: 681.2703383169155 for episode: 39 and reward: 859.0044761397314\n",
      "Average value: 692.8713649299955 for episode: 40 and reward: 913.2908705785136\n",
      "Average value: 697.0269540312046 for episode: 41 and reward: 775.9831469541783\n",
      "Average value: 700.4094148713322 for episode: 42 and reward: 764.6761708337564\n",
      "Average value: 708.703658828356 for episode: 43 and reward: 866.2942940118082\n",
      "Average value: 708.4051993946055 for episode: 44 and reward: 702.7344701533447\n",
      "Average value: 716.0719829095514 for episode: 45 and reward: 861.740869693524\n",
      "Average value: 726.725875869216 for episode: 46 and reward: 929.1498421028459\n",
      "Average value: 734.1292543836759 for episode: 47 and reward: 874.7934461584148\n",
      "Average value: 742.9256556955214 for episode: 48 and reward: 910.0572806205885\n",
      "Average value: 741.7724092045153 for episode: 49 and reward: 719.8607258753998\n",
      "Average value: 751.4248918728438 for episode: 50 and reward: 934.8220625710848\n",
      "Average value: 756.3189094215746 for episode: 51 and reward: 849.3052428474608\n",
      "Average value: 761.8373417782989 for episode: 52 and reward: 866.687556556061\n",
      "Average value: 769.0076210598611 for episode: 53 and reward: 905.2429274095443\n",
      "Average value: 776.2937430905789 for episode: 54 and reward: 914.7300616742167\n",
      "Average value: 774.4617312470423 for episode: 55 and reward: 739.6535062198473\n",
      "Average value: 756.8114254903845 for episode: 56 and reward: 421.45561611388774\n",
      "Average value: 764.1325596624765 for episode: 57 and reward: 903.2341089322234\n",
      "Average value: 771.5364407430388 for episode: 58 and reward: 912.210181273725\n",
      "Average value: 778.058537890893 for episode: 59 and reward: 901.9783837001229\n",
      "Average value: 784.1457054755244 for episode: 60 and reward: 899.8018895835195\n",
      "Average value: 787.4688869223421 for episode: 61 and reward: 850.6093344118782\n",
      "Average value: 786.2760510825993 for episode: 62 and reward: 763.6121701274883\n",
      "Average value: 767.5602861167744 for episode: 63 and reward: 411.96075176610015\n",
      "Average value: 756.4508663884504 for episode: 64 and reward: 545.3718915502961\n",
      "Average value: 722.7818261322483 for episode: 65 and reward: 83.0700612644101\n",
      "Average value: 726.3261235796435 for episode: 66 and reward: 793.6677750801558\n",
      "Average value: 733.9288522006755 for episode: 67 and reward: 878.380696000283\n",
      "Average value: 724.2700644116178 for episode: 68 and reward: 540.753096419523\n",
      "Average value: 726.111805616666 for episode: 69 and reward: 761.1048885125821\n",
      "Average value: 728.6383959157383 for episode: 70 and reward: 776.6436115981139\n",
      "Average value: 716.4495519271721 for episode: 71 and reward: 484.8615161444156\n",
      "Average value: 705.077665324147 for episode: 72 and reward: 489.0118198666707\n",
      "Average value: 700.7227890158734 for episode: 73 and reward: 617.9801391586763\n",
      "Average value: 687.5147089661848 for episode: 74 and reward: 436.5611880221022\n",
      "Average value: 683.1271253307727 for episode: 75 and reward: 599.7630362579442\n",
      "Average value: 694.0865083380002 for episode: 76 and reward: 902.3147854753204\n",
      "Average value: 705.7896870975122 for episode: 77 and reward: 928.150083528242\n",
      "Average value: 714.2019781285248 for episode: 78 and reward: 874.0355077177643\n",
      "Average value: 722.4154788105866 for episode: 79 and reward: 878.471991769762\n",
      "Average value: 731.9436539311466 for episode: 80 and reward: 912.9789812217889\n",
      "Average value: 739.2920095518234 for episode: 81 and reward: 878.9107663446849\n",
      "Average value: 747.3374583569391 for episode: 82 and reward: 900.2009856541363\n",
      "Average value: 756.9268965753221 for episode: 83 and reward: 939.1262227245987\n",
      "Average value: 764.9164120616339 for episode: 84 and reward: 916.7172063015605\n",
      "Average value: 772.7099461023217 for episode: 85 and reward: 920.7870928753908\n",
      "Average value: 780.8116732876952 for episode: 86 and reward: 934.7444898097915\n",
      "Average value: 787.3831052793685 for episode: 87 and reward: 912.2403131211629\n",
      "Average value: 794.1588368162309 for episode: 88 and reward: 922.8977360166166\n",
      "Average value: 800.6973434860189 for episode: 89 and reward: 924.928970211993\n",
      "Average value: 806.2197729101998 for episode: 90 and reward: 911.1459319696372\n",
      "Average value: 811.8633744909658 for episode: 91 and reward: 919.0918045255215\n",
      "Average value: 816.6486165150543 for episode: 92 and reward: 907.5682149727369\n",
      "Average value: 820.4986560171585 for episode: 93 and reward: 893.6494065571399\n",
      "Average value: 824.7690002965642 for episode: 94 and reward: 905.9055416052737\n",
      "Average value: 829.1806408207111 for episode: 95 and reward: 913.0018107795034\n",
      "Average value: 833.2159784033593 for episode: 96 and reward: 909.8873924736748\n",
      "Average value: 835.3766234831702 for episode: 97 and reward: 876.4288799995769\n",
      "Average value: 833.8377108788968 for episode: 98 and reward: 804.5983713977025\n",
      "Average value: 830.7413871743123 for episode: 99 and reward: 771.9112367872073\n",
      "Average value: 834.0137661730183 for episode: 100 and reward: 896.1889671484316\n",
      "Average value: 833.720739831697 for episode: 101 and reward: 828.1532393465902\n",
      "Average value: 837.3715170095535 for episode: 102 and reward: 906.7362833888268\n",
      "Average value: 812.8326009564261 for episode: 103 and reward: 346.5931959470055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value: 810.7373996339226 for episode: 104 and reward: 770.9285745063564\n",
      "Average value: 804.408861394853 for episode: 105 and reward: 684.1666348525346\n",
      "Average value: 805.5079174747749 for episode: 106 and reward: 826.3899829932923\n",
      "Average value: 809.9155784592241 for episode: 107 and reward: 893.6611371637597\n",
      "Average value: 814.1850037932121 for episode: 108 and reward: 895.3040851389852\n",
      "Average value: 816.0016140524036 for episode: 109 and reward: 850.5172089770443\n",
      "Average value: 816.9854160976804 for episode: 110 and reward: 835.6776549579395\n",
      "Average value: 797.9435918350823 for episode: 111 and reward: 436.1489308457202\n",
      "Average value: 796.208311930905 for episode: 112 and reward: 763.2379937515369\n",
      "Average value: 760.9221445449258 for episode: 113 and reward: 90.48496421132204\n",
      "Average value: 767.9084322414899 for episode: 114 and reward: 900.6478984762094\n",
      "Average value: 774.7777015314616 for episode: 115 and reward: 905.2938180409247\n",
      "Average value: 756.34866004109 for episode: 116 and reward: 406.19687172402956\n",
      "Average value: 744.6292704367072 for episode: 117 and reward: 521.9608679534316\n",
      "Average value: 751.4083346977189 for episode: 118 and reward: 880.210555656943\n",
      "Average value: 758.8601296216697 for episode: 119 and reward: 900.4442331767326\n",
      "Average value: 766.3226260147793 for episode: 120 and reward: 908.1100574838637\n",
      "Average value: 772.4566489914642 for episode: 121 and reward: 889.0030855484789\n",
      "Average value: 774.8242494320165 for episode: 122 and reward: 819.8086578025094\n",
      "Average value: 777.7920814919098 for episode: 123 and reward: 834.1808906298837\n",
      "Average value: 783.3154223946585 for episode: 124 and reward: 888.2588995468866\n",
      "Average value: 788.8705730797816 for episode: 125 and reward: 894.4184360971208\n",
      "Average value: 793.5190080625102 for episode: 126 and reward: 881.8392727343556\n",
      "Average value: 798.5756532371416 for episode: 127 and reward: 894.6519115551387\n",
      "Average value: 802.94313600427 for episode: 128 and reward: 885.9253085797086\n",
      "Average value: 808.0518954015766 for episode: 129 and reward: 905.1183239504061\n",
      "Average value: 810.0338683625447 for episode: 130 and reward: 847.6913546209381\n",
      "Average value: 793.2415278574837 for episode: 131 and reward: 474.1870582613257\n",
      "Average value: 791.9325255178545 for episode: 132 and reward: 767.0614810649021\n",
      "Average value: 792.7126821614627 for episode: 133 and reward: 807.5356583900169\n",
      "Average value: 798.9573072066291 for episode: 134 and reward: 917.6051830647936\n",
      "Average value: 804.3255002490954 for episode: 135 and reward: 906.321168055957\n",
      "Average value: 809.6309521616854 for episode: 136 and reward: 910.4345385008971\n",
      "Average value: 815.5892763987376 for episode: 137 and reward: 928.7974369027312\n",
      "Average value: 819.095362152994 for episode: 138 and reward: 885.7109914838662\n",
      "Average value: 807.2850577409564 for episode: 139 and reward: 582.8892739122433\n",
      "Average value: 812.7958734982684 for episode: 140 and reward: 917.5013728871979\n",
      "Average value: 804.5633725021672 for episode: 141 and reward: 648.1458535762443\n",
      "Average value: 810.8478185590936 for episode: 142 and reward: 930.2522936406978\n",
      "Average value: 816.8242559301278 for episode: 143 and reward: 930.3765659797781\n",
      "Average value: 811.7447541443164 for episode: 144 and reward: 715.2342202139002\n",
      "Average value: 817.0763289612104 for episode: 145 and reward: 918.376250482196\n",
      "Average value: 823.5245027691554 for episode: 146 and reward: 946.039805120112\n",
      "Average value: 828.8760657447772 for episode: 147 and reward: 930.5557622815893\n",
      "Average value: 832.6358967450982 for episode: 148 and reward: 904.0726857511991\n",
      "Average value: 834.2847896823538 for episode: 149 and reward: 865.6137554902092\n",
      "Average value: 834.3129638070723 for episode: 150 and reward: 834.8482721767242\n",
      "Average value: 839.0551364288215 for episode: 151 and reward: 929.156416242057\n",
      "Average value: 843.2586655495085 for episode: 152 and reward: 923.1257188425616\n",
      "Average value: 840.4186957923539 for episode: 153 and reward: 786.4592704064178\n",
      "Average value: 840.179684154857 for episode: 154 and reward: 835.6384630424167\n",
      "Average value: 844.2892575053189 for episode: 155 and reward: 922.3711511640952\n",
      "Average value: 847.5134893037584 for episode: 156 and reward: 908.773893474111\n",
      "Average value: 850.9385674146923 for episode: 157 and reward: 916.0150515224374\n",
      "Average value: 855.4753720547832 for episode: 158 and reward: 941.6746602165102\n",
      "Average value: 859.4750168886678 for episode: 159 and reward: 935.468268732478\n",
      "Average value: 862.9929982453381 for episode: 160 and reward: 929.8346440220744\n",
      "Average value: 866.1928815807211 for episode: 161 and reward: 926.9906649529983\n",
      "Average value: 868.8136228733736 for episode: 162 and reward: 918.6077074337712\n",
      "Average value: 870.0700790684373 for episode: 163 and reward: 893.9427467746489\n",
      "Average value: 873.6197560527692 for episode: 164 and reward: 941.0636187550775\n",
      "Average value: 876.787043804685 for episode: 165 and reward: 936.9655110910855\n",
      "Average value: 880.2961108217078 for episode: 166 and reward: 946.9683841451408\n",
      "Average value: 883.4076815531122 for episode: 167 and reward: 942.5275254497974\n",
      "Average value: 886.4952272800576 for episode: 168 and reward: 945.1585960920214\n",
      "Average value: 889.7978730859234 for episode: 169 and reward: 952.5481433973742\n",
      "Average value: 892.64928394899 for episode: 170 and reward: 946.8260903472575\n",
      "Average value: 893.3490038650859 for episode: 171 and reward: 906.6436822709089\n",
      "Average value: 892.2720903160375 for episode: 172 and reward: 871.8107328841191\n",
      "Average value: 884.9821408382111 for episode: 173 and reward: 746.4731007595103\n",
      "Average value: 883.1999882738459 for episode: 174 and reward: 849.3390895509087\n",
      "Average value: 886.4415844947654 for episode: 175 and reward: 948.0319126922366\n",
      "Average value: 890.2982044188628 for episode: 176 and reward: 963.5739829767148\n",
      "Average value: 893.7857109992266 for episode: 177 and reward: 960.0483360261386\n",
      "Average value: 896.6837759341786 for episode: 178 and reward: 951.747009698267\n",
      "Average value: 900.4217108843684 for episode: 179 and reward: 971.4424749379765\n",
      "Average value: 903.6103762678855 for episode: 180 and reward: 964.1950185547104\n",
      "Average value: 906.2911533460904 for episode: 181 and reward: 957.2259178319841\n",
      "Average value: 885.207058768484 for episode: 182 and reward: 484.60926179396535\n",
      "Average value: 888.7687280592692 for episode: 183 and reward: 956.4404445841892\n",
      "Average value: 891.9137335334581 for episode: 184 and reward: 951.668837543048\n",
      "Average value: 891.2321318315151 for episode: 185 and reward: 878.2816994945995\n",
      "Average value: 890.9204005721584 for episode: 186 and reward: 884.9975066443832\n",
      "Average value: 876.9655939785985 for episode: 187 and reward: 611.8242687009582\n",
      "Average value: 877.5343579225041 for episode: 188 and reward: 888.3408728567133\n",
      "Average value: 870.5983228659558 for episode: 189 and reward: 738.813656791537\n",
      "Average value: 873.7039186956083 for episode: 190 and reward: 932.7102394590069\n",
      "Average value: 864.2103870163438 for episode: 191 and reward: 683.8332851103195\n",
      "Average value: 864.1202837946169 for episode: 192 and reward: 862.4083225818041\n",
      "Average value: 846.008276413486 for episode: 193 and reward: 501.8801361720012\n",
      "Average value: 838.2810158495896 for episode: 194 and reward: 691.463065135558\n",
      "Average value: 816.5386921674883 for episode: 195 and reward: 403.4345422075637\n",
      "Average value: 823.372941819678 for episode: 196 and reward: 953.223685211283\n",
      "Average value: 828.1520369328316 for episode: 197 and reward: 918.9548440827496\n",
      "Average value: 822.2998749565394 for episode: 198 and reward: 711.1087974069861\n",
      "Average value: 826.48026811924 for episode: 199 and reward: 905.9077382105532\n",
      "Average value: 807.1196342403985 for episode: 200 and reward: 439.26759054241023\n",
      "Average value: 781.0787900596969 for episode: 201 and reward: 286.302750626366\n",
      "Average value: 767.1725325710007 for episode: 202 and reward: 502.9536402857745\n",
      "Average value: 755.3176292333932 for episode: 203 and reward: 530.0744658188491\n",
      "Average value: 757.313778929773 for episode: 204 and reward: 795.24062316099\n",
      "Average value: 762.9851750835483 for episode: 205 and reward: 870.74170200528\n",
      "Average value: 771.3509124113308 for episode: 206 and reward: 930.2999216391997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value: 780.177040126587 for episode: 207 and reward: 947.873466716456\n",
      "Average value: 787.3262955082384 for episode: 208 and reward: 923.1621477596152\n",
      "Average value: 791.2000961240246 for episode: 209 and reward: 864.8023078239632\n",
      "Average value: 798.9970685746943 for episode: 210 and reward: 947.139545137418\n",
      "Average value: 805.2858354252089 for episode: 211 and reward: 924.7724055849886\n",
      "Average value: 811.0853178013323 for episode: 212 and reward: 921.2754829476761\n",
      "Average value: 816.4124110083762 for episode: 213 and reward: 917.6271819422122\n",
      "Average value: 819.4771536044898 for episode: 214 and reward: 877.7072629306481\n",
      "Average value: 822.6298612060917 for episode: 215 and reward: 882.5313056365304\n",
      "Average value: 822.8914689271337 for episode: 216 and reward: 827.8620156269318\n",
      "Average value: 824.3612601685035 for episode: 217 and reward: 852.287293754529\n",
      "Average value: 829.7109675091646 for episode: 218 and reward: 931.3554069817266\n",
      "Average value: 833.885947799228 for episode: 219 and reward: 913.2105733104333\n",
      "Average value: 838.7117946968527 for episode: 220 and reward: 930.4028857517236\n",
      "Average value: 842.8350128765842 for episode: 221 and reward: 921.1761582914834\n",
      "Average value: 845.6937620948778 for episode: 222 and reward: 900.0099972424574\n",
      "Average value: 849.1941917137929 for episode: 223 and reward: 915.7023544731808\n",
      "Average value: 843.6004904330225 for episode: 224 and reward: 737.3201660983856\n",
      "Average value: 845.3933498880284 for episode: 225 and reward: 879.4576795331405\n",
      "Average value: 848.0410215793679 for episode: 226 and reward: 898.3467837148196\n",
      "Average value: 848.7830649607512 for episode: 227 and reward: 862.8818892070339\n",
      "Average value: 847.6318034745174 for episode: 228 and reward: 825.7578352360748\n",
      "Average value: 846.987182172516 for episode: 229 and reward: 834.7393774344916\n",
      "Average value: 849.6150398689464 for episode: 230 and reward: 899.5443361011249\n",
      "Average value: 852.8731390592941 for episode: 231 and reward: 914.777023675902\n",
      "Average value: 854.0037802805402 for episode: 232 and reward: 875.4859634842189\n",
      "Average value: 835.1829451297476 for episode: 233 and reward: 477.5870772646886\n",
      "Average value: 765.075643374133 for episode: 234 and reward: -566.9630899825447\n",
      "Average value: 698.1152963929698 for episode: 235 and reward: -574.1312962491324\n",
      "Average value: 665.6744660852047 for episode: 236 and reward: 49.29869023766869\n",
      "Average value: 660.37453911437 for episode: 237 and reward: 559.6759266685124\n",
      "Average value: 654.6970961927258 for episode: 238 and reward: 546.8256806814867\n",
      "Average value: 660.2295146053953 for episode: 239 and reward: 765.3454644461157\n",
      "Average value: 670.5891808601501 for episode: 240 and reward: 867.4228397004928\n",
      "Average value: 682.2673074800252 for episode: 241 and reward: 904.1517132576529\n",
      "Average value: 693.1476359942919 for episode: 242 and reward: 899.8738777653612\n",
      "Average value: 689.4494950445602 for episode: 243 and reward: 619.1848169996565\n",
      "Average value: 689.7907758263328 for episode: 244 and reward: 696.2751106800143\n",
      "Average value: 700.1784033471284 for episode: 245 and reward: 897.5433262422454\n",
      "Average value: 704.024214652454 for episode: 246 and reward: 777.0946294536418\n",
      "Average value: 709.2194212447829 for episode: 247 and reward: 807.9283464990326\n",
      "Average value: 716.6174221990753 for episode: 248 and reward: 857.1794403306326\n",
      "Average value: 726.4717951872939 for episode: 249 and reward: 913.7048819634467\n",
      "Average value: 737.3324223063523 for episode: 250 and reward: 943.6843375684622\n",
      "Average value: 746.1265958704688 for episode: 251 and reward: 913.2158935886833\n",
      "Average value: 752.5219905406199 for episode: 252 and reward: 874.0344892734896\n",
      "Average value: 760.6426055074456 for episode: 253 and reward: 914.9342898771354\n",
      "Average value: 769.4514308023362 for episode: 254 and reward: 936.8191114052576\n",
      "Average value: 774.7121613317639 for episode: 255 and reward: 874.6660413908915\n",
      "Average value: 780.8115927997542 for episode: 256 and reward: 896.7007906915717\n",
      "Average value: 785.8062752821844 for episode: 257 and reward: 880.7052424483599\n",
      "Average value: 790.0387847642287 for episode: 258 and reward: 870.4564649230696\n",
      "Average value: 797.203262212904 for episode: 259 and reward: 933.328333737734\n",
      "Average value: 803.2689746141382 for episode: 260 and reward: 918.5175102375897\n",
      "Average value: 808.0325111503008 for episode: 261 and reward: 898.5397053373913\n",
      "Average value: 804.2536841589324 for episode: 262 and reward: 732.4559713229339\n",
      "Average value: 803.1359120317866 for episode: 263 and reward: 781.8982416160146\n",
      "Average value: 802.568071712724 for episode: 264 and reward: 791.7791056505338\n",
      "Average value: 804.2303350999866 for episode: 265 and reward: 835.8133394579773\n",
      "Average value: 794.987719298907 for episode: 266 and reward: 619.378019078395\n",
      "Average value: 793.5756719564904 for episode: 267 and reward: 766.7467724505761\n",
      "Average value: 791.8205372125368 for episode: 268 and reward: 758.4729770774204\n",
      "Average value: 779.5159384744312 for episode: 269 and reward: 545.7285624504271\n",
      "Average value: 768.1068386626295 for episode: 270 and reward: 551.3339422383982\n",
      "Average value: 760.2821185623899 for episode: 271 and reward: 611.6124366578373\n",
      "Average value: 751.6717861262092 for episode: 272 and reward: 588.0754698387781\n",
      "Average value: 742.1331139521483 for episode: 273 and reward: 560.8983426449902\n",
      "Average value: 744.7887473360113 for episode: 274 and reward: 795.2457816294108\n",
      "Average value: 754.6893444203226 for episode: 275 and reward: 942.8006890222402\n",
      "Average value: 764.3092009936705 for episode: 276 and reward: 947.0864758872816\n",
      "Average value: 772.8159680915057 for episode: 277 and reward: 934.4445429503755\n",
      "Average value: 777.9509976462682 for episode: 278 and reward: 875.5165591867567\n",
      "Average value: 779.2220808979947 for episode: 279 and reward: 803.3726626808\n",
      "Average value: 763.1693932024277 for episode: 280 and reward: 458.1683269866559\n",
      "Average value: 764.8703343404623 for episode: 281 and reward: 797.1882159631194\n",
      "Average value: 774.8004643941746 for episode: 282 and reward: 963.4729354147098\n",
      "Average value: 783.772324229053 for episode: 283 and reward: 954.2376610917435\n",
      "Average value: 778.5397852712015 for episode: 284 and reward: 679.1215450720244\n",
      "Average value: 786.6053500127125 for episode: 285 and reward: 939.8510801014243\n",
      "Average value: 795.2756807584205 for episode: 286 and reward: 960.0119649268731\n",
      "Average value: 803.5510675957606 for episode: 287 and reward: 960.7834175052213\n",
      "Average value: 811.3889717112479 for episode: 288 and reward: 960.3091499055066\n",
      "Average value: 818.5669590928566 for episode: 289 and reward: 954.9487193434213\n",
      "Average value: 825.3631470215997 for episode: 290 and reward: 954.4907176677193\n",
      "Average value: 831.4789766081824 for episode: 291 and reward: 947.6797387532542\n",
      "Average value: 837.7965889840767 for episode: 292 and reward: 957.8312241260678\n",
      "Average value: 843.6614076874663 for episode: 293 and reward: 955.0929630518672\n",
      "Average value: 848.5797246485773 for episode: 294 and reward: 942.0277469096868\n",
      "Average value: 853.9467371422196 for episode: 295 and reward: 955.9199745214232\n",
      "Average value: 859.3335602622293 for episode: 296 and reward: 961.6831995424153\n",
      "Average value: 863.9721914556337 for episode: 297 and reward: 952.1061841303193\n",
      "Average value: 868.5228475211042 for episode: 298 and reward: 954.9853127650431\n",
      "Average value: 872.0454692810908 for episode: 299 and reward: 938.9752827208405\n",
      "Average value: 875.0341930707406 for episode: 300 and reward: 931.8199450740876\n",
      "Average value: 878.6747571637117 for episode: 301 and reward: 947.8454749301632\n",
      "Average value: 881.8253459248924 for episode: 302 and reward: 941.6865323873269\n",
      "Average value: 884.2198745386959 for episode: 303 and reward: 929.7159182009602\n",
      "Average value: 886.0711540920722 for episode: 304 and reward: 921.245465606224\n",
      "Average value: 887.2511044301546 for episode: 305 and reward: 909.6701608537201\n",
      "Average value: 885.5189122754757 for episode: 306 and reward: 852.6072613365803\n",
      "Average value: 885.9438674353817 for episode: 307 and reward: 894.0180154735963\n",
      "Average value: 881.7889124989341 for episode: 308 and reward: 802.8447687064321\n",
      "Average value: 881.2486828677372 for episode: 309 and reward: 870.9843198749963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average value: 883.4624427617407 for episode: 310 and reward: 925.5238807478064\n",
      "Average value: 871.4351382329783 for episode: 311 and reward: 642.9163521864921\n",
      "Average value: 872.5750380746779 for episode: 312 and reward: 894.2331350669712\n",
      "Average value: 875.4345593892291 for episode: 313 and reward: 929.7654643657038\n",
      "Average value: 878.7411411198752 for episode: 314 and reward: 941.5661940021531\n",
      "Average value: 851.862191569894 for episode: 315 and reward: 341.16215012025083\n",
      "Average value: 810.1205232382085 for episode: 316 and reward: 17.028824936185824\n",
      "Average value: 790.2201813318261 for episode: 317 and reward: 412.11368511055963\n",
      "Average value: 789.0720530628735 for episode: 318 and reward: 767.2576159527744\n",
      "Average value: 784.9959564013728 for episode: 319 and reward: 707.5501198328609\n",
      "Average value: 791.2682139874926 for episode: 320 and reward: 910.4411081237686\n",
      "Average value: 796.7160339699947 for episode: 321 and reward: 900.2246136375367\n",
      "Average value: 802.7245013500135 for episode: 322 and reward: 916.8853815703718\n",
      "Average value: 789.380217230171 for episode: 323 and reward: 535.8388189531644\n",
      "Average value: 787.0198965088158 for episode: 324 and reward: 742.1738028030687\n",
      "Average value: 792.8414835758886 for episode: 325 and reward: 903.4516378502709\n",
      "Average value: 796.4172473494768 for episode: 326 and reward: 864.3567590476548\n",
      "Average value: 792.3349979681027 for episode: 327 and reward: 714.772259721994\n",
      "Average value: 795.7871412421404 for episode: 328 and reward: 861.3778634488568\n",
      "Average value: 783.9456563040785 for episode: 329 and reward: 558.957442480904\n",
      "Average value: 783.0853449948211 for episode: 330 and reward: 766.7394301189308\n",
      "Average value: 765.881843358692 for episode: 331 and reward: 439.0153122722408\n",
      "Average value: 747.3113584364089 for episode: 332 and reward: 394.47214491303254\n",
      "Average value: 751.8400359017703 for episode: 333 and reward: 837.8849077436361\n",
      "Average value: 743.6279746043065 for episode: 334 and reward: 587.5988099524936\n",
      "Average value: 746.1976919821791 for episode: 335 and reward: 795.0223221617592\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2e5095b01084>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddpg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action_with_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ece276_project/ddpg.py\u001b[0m in \u001b[0;36mget_action_with_noise\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_action_with_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0metc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m         \"\"\"\n\u001b[0;32m--> 896\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \"\"\"\n\u001b[0;32m--> 883\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mmodules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_modules'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmodules\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m                     raise AttributeError(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from ddpg import *\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Environments to be tested on\n",
    "# env_name = 'InvertedPendulum-v1'\n",
    "# env_name = 'Pendulum-v0'\n",
    "# env_name = 'HalfCheetah-v1'\n",
    "env_name = 'Ant-v1'\n",
    "# env_name = \"Hopper-v1\"\n",
    "# env_name = \"Walker2d-v1\"\n",
    "\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "MAX_STEPS = 1000\n",
    "NUM_EPISODES = 1200\n",
    "\n",
    "logging_interval = 100\n",
    "animate_interval = logging_interval * 5\n",
    "\n",
    "VISUALIZE = False\n",
    "\n",
    "dropout_rate = 0.05\n",
    "Records = []\n",
    "\n",
    "\n",
    "env = gym.make(env_name)\n",
    "env = NormalizeAction(env)  # remap action values for the environment\n",
    "avg_val = 0\n",
    "\n",
    "# for plotting\n",
    "running_rewards_ddpg = []\n",
    "step_list_ddpg = []\n",
    "step_counter = 0\n",
    "\n",
    "# set term_condition for early stopping according to environment being used\n",
    "term_condition = 1500  # Pendulum\n",
    "ddpg = DDPG(act_dim = env.action_space.shape[0], obs_dim = env.observation_space.shape[0],critic_lr=1e-3, actor_lr=1e-4, gamma = GAMMA, batch_size = BATCH_SIZE)\n",
    "\n",
    "for itr in range(NUM_EPISODES):\n",
    "    state = env.reset()  # get initial state\n",
    "    animate_this_episode = (itr % animate_interval == 0) and VISUALIZE\n",
    "    total_reward = 0\n",
    "\n",
    "    while True:\n",
    "        ddpg.noise.reset()\n",
    "\n",
    "        if animate_this_episode:\n",
    "            env.render()\n",
    "            time.sleep(0.05)\n",
    "\n",
    "        action = ddpg.get_action_with_noise(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        ddpg.replayBuffer.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        step_counter += 1\n",
    "\n",
    "        # use actor to get action, add ddpg.noise.step() to action\n",
    "        # remember to put NN in eval mode while testing (to deal with BatchNorm layers) and put it back\n",
    "        # to train mode after you're done getting the action\n",
    "\n",
    "        # step action, get next state, reward, done (keep track of total_reward)\n",
    "        # populate ddpg.replayBuffer\n",
    "        if ddpg.replayBuffer.size > BATCH_SIZE:\n",
    "            ddpg.train()\n",
    "        \n",
    "\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    if avg_val > term_condition and itr > 100:\n",
    "        #save(ddpg)\n",
    "        break\n",
    "        \n",
    "    \n",
    "\n",
    "    running_rewards_ddpg.append(total_reward)  # return of this episode\n",
    "    step_list_ddpg.append(step_counter)\n",
    "    \n",
    "    \n",
    "    #dropout\n",
    "#     number_to_drop = int(ddpg.replayBuffer.size * dropout_rate)\n",
    "#     for i in range(number_to_drop):\n",
    "#         del ddpg.replayBuffer.buffer[np.random.choice(len(ddpg.replayBuffer.buffer),1)[0]]\n",
    "#         ddpg.replayBuffer.size -=1\n",
    "            \n",
    "\n",
    "    avg_val = avg_val * 0.95 + 0.05 * running_rewards_ddpg[-1]\n",
    "    print(\"Average value: {} for episode: {} and reward: {}\".format(avg_val, itr,total_reward))\n",
    "    Records.append((avg_val,itr,step_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"ant.pkl\",\"wb\") as f:\n",
    "    pickle.dump((Records,running_rewards_ddpg),f)\n",
    "    \n",
    "    \n",
    "with open(\"ant_model.pkl\",\"wb\") as f:\n",
    "    pickle.dump(ddpg,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
